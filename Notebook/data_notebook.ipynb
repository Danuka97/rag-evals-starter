{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10fd77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Installing collected packages: fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.5.0\n",
      "    Uninstalling fsspec-2025.5.0:\n",
      "      Successfully uninstalled fsspec-2025.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-core 0.12.3 requires pydantic<2.10.0,>=2.7.0, but you have pydantic 2.11.5 which is incompatible.\n",
      "rag 0.1.0 requires google-adk<0.6.0,>=0.5.0, but you have google-adk 0.0.1 which is incompatible.\n",
      "rag 0.1.0 requires google-auth<3.0.0,>=2.36.0, but you have google-auth 1.35.0 which is incompatible.\n",
      "rag 0.1.0 requires google-cloud-aiplatform[adk,agent-engines]<2.0.0,>=1.93.0, but you have google-cloud-aiplatform 0.9.0 which is incompatible.\n",
      "rag 0.1.0 requires requests<3.0.0,>=2.32.3, but you have requests 2.32.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-4.0.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb0da86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 960/960 [00:00<00:00, 49463.56 examples/s]\n",
      "Generating test split: 100%|██████████| 240/240 [00:00<00:00, 25470.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'test'])\n",
      "{'context': 'Francisco Rogers found the answer to a search query collar george herbert essay\\nLink ----> collar george herbert essay\\nWrite my essay ESSAYERUDITE.COM\\nconstitution research paper ideas\\ndefinition essay humility\\nbusiness strategy case study solution\\ncorporals course essay\\ndecisions in paradise essays\\ncollege essay word count\\ncredit cart terminal paper\\nbyron don juan essay\\ndemocratic party essays\\ncoursework language learning material teaching\\nchristmas commercialized essay\\ndahrendorf essays theory society\\nbuy apa format essay buy apa format essay\\nconan doyle speckled band essay\\ncollege essay application prompt\\ncolumbia university mfa creative writing acceptance rate\\ncrucible coursework questions\\ncollege essay topics texas\\ncover letter thesis proposal\\nciting ma thesis\\ncompare and contrast essays for elementary\\ncoursework completed without degree\\ncomparison islam christianity essay\\ncheerleading stereotypes essay\\ncultural diversity college essay\\ncritical thinking article analysis\\ncusat online thesis\\ncritical thinking problems for 2nd graders\\ncritical review of literature\\ndirty pretty things movie essay\\ndiscuss significance essay\\ndid king arthur exist essay\\nconfucius essay example\\ndescription of las vegas for essay\\ncover page for research paper\\ncommon app essay should have title\\ncreative writing colleges in north carolina\\ncritical essays on anthony burgess geoffrey aggeler\\ncatcher in the rye essays symbolism\\ncas reflective essay\\nclose reading essay\\ncan someone revise my essay\\nchild labour essays india\\ndevelopment business plan\\ndefinition essay of love\\nchinese dictionary\\ncite scientific research paper\\ncornell architecture thesis book\\ncomposition essay definition\\nca display cfm ethesis_id 1139\\nbusiness proposal format\\ncritical thinking skills activities for kindergarten\\ncatcher in the rye religion essay\\ncoursecompass com\\ndeath salesman tragedy essay questions\\ndignity of labour essay for children\\ncritical assessment definition\\ncomparison and contrast essay on high school and college\\nclass homework a pickett\\nbuffy the vampire slayer thesis\\ncustomer satisfaction essay\\nchildhood obesity argument essay\\ncauses of ww2 essay questions\\ncompare contrast essay introduction write\\ncopd case study nursing scribd\\ndiscussion essay format\\ncreative title for of mice and men essay\\ncompass writing essay practice test page\\ncollege short essay format\\ndifferences between personal narrative research paper\\ncompare contast essay', 'question': 'Who found the answer to a search query collar george herbert essay?', 'answer': 'Francisco Rogers found the answer to a search query collar george herbert essay.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Example: neural-bridge/rag-dataset-1200\n",
    "dataset = load_dataset(\"neural-bridge/rag-dataset-1200\")\n",
    "\n",
    "# View train/test split\n",
    "print(dataset.keys())     \n",
    "\n",
    "# Inspect sample output\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f479dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.79ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 63.46ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "923350"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].to_csv(\"rag_dataset_train.csv\", index=False)\n",
    "dataset[\"test\"].to_csv(\"rag_dataset_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5ae6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answer'],\n",
       "    num_rows: 960\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f406e1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trail Patrol Training\\nWant to be a part of th...</td>\n",
       "      <td>What are some of the skills taught in the Trai...</td>\n",
       "      <td>The course teaches the essential skills necess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lot Of Cbi Theater Ww2 Letters, 2 Newspapers, ...</td>\n",
       "      <td>Who was the original owner of the lot of items...</td>\n",
       "      <td>The original lot of items belonged to Lt. Neil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just.\\nWe are a small all volunteer NGO Humani...</td>\n",
       "      <td>What is the main objective of Humanity Road as...</td>\n",
       "      <td>The main objective of Humanity Road is to 'clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of two convicted killers who escaped from ...</td>\n",
       "      <td>Who were the two convicted killers that escape...</td>\n",
       "      <td>The two convicted killers that escaped from an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Continued from Part 1...)\\n(Thirty years late...</td>\n",
       "      <td>Who was the person that came to help when Isaa...</td>\n",
       "      <td>Jesus was the person who came to help when Isa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Trail Patrol Training\\nWant to be a part of th...   \n",
       "1  Lot Of Cbi Theater Ww2 Letters, 2 Newspapers, ...   \n",
       "2  Just.\\nWe are a small all volunteer NGO Humani...   \n",
       "3  One of two convicted killers who escaped from ...   \n",
       "4  (Continued from Part 1...)\\n(Thirty years late...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What are some of the skills taught in the Trai...   \n",
       "1  Who was the original owner of the lot of items...   \n",
       "2  What is the main objective of Humanity Road as...   \n",
       "3  Who were the two convicted killers that escape...   \n",
       "4  Who was the person that came to help when Isaa...   \n",
       "\n",
       "                                              answer  \n",
       "0  The course teaches the essential skills necess...  \n",
       "1  The original lot of items belonged to Lt. Neil...  \n",
       "2  The main objective of Humanity Road is to 'clo...  \n",
       "3  The two convicted killers that escaped from an...  \n",
       "4  Jesus was the person who came to help when Isa...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test =pd.read_csv(\"/Users/danukatheja/Downloads/rag-eval/rag-evals-starter/data/rag_dataset_test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d9dc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danukatheja/miniconda3/envs/adk_test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "def hf_split_to_rag_jsonl(\n",
    "    dataset_name: str,\n",
    "    split: str,\n",
    "    out_path: str,\n",
    "    *,\n",
    "    context_col: str = \"context\",\n",
    "    question_col: str = \"question\",\n",
    "    answer_col: str = \"answer\",\n",
    "    include_q_and_a_in_content: bool = False,\n",
    "    streaming: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Streams the split (if streaming=True) and writes JSONL compatible with Vertex RAG Engine.\n",
    "    \"\"\"\n",
    "    ds = load_dataset(dataset_name, split=split, streaming=streaming)\n",
    "\n",
    "    out = pathlib.Path(out_path)\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for i, row in enumerate(ds):\n",
    "            # robust getters\n",
    "            ctx = str(row.get(context_col, \"\") or \"\")\n",
    "            q = str(row.get(question_col, \"\") or \"\")\n",
    "            a = str(row.get(answer_col, \"\") or \"\")\n",
    "            rid = str(row.get(\"id\") or f\"{dataset_name.replace('/','_')}_{split}_{i:06d}\")\n",
    "\n",
    "            if include_q_and_a_in_content:\n",
    "                content = f\"Context:\\n{ctx}\\n\\nQuestion:\\n{q}\\n\\nAnswer:\\n{a}\"\n",
    "                md = {\"dataset\": dataset_name, \"split\": split}\n",
    "            else:\n",
    "                content = ctx\n",
    "                md = {\n",
    "                    \"question\": q or None,\n",
    "                    \"answer\": a or None,\n",
    "                    \"dataset\": dataset_name,\n",
    "                    \"split\": split,\n",
    "                }\n",
    "                md = {k: v for k, v in md.items() if v not in (None, \"\")}\n",
    "\n",
    "            f.write(json.dumps({\"id\": rid, \"content\": content, \"metadata\": md}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# ---- Example usage (HF) ----\n",
    "# hf_split_to_rag_jsonl(\"neural-bridge/rag-dataset-1200\", \"train\", \"out/hf_qa_train.jsonl\",\n",
    "#                       include_q_and_a_in_content=False, streaming=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9676e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put this at the very top of your script\n",
    "from datasets import config as ds_config\n",
    "ds_config.TORCH_AVAILABLE = False  # force datasets to not import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937f53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Example usage (HF) ----\n",
    "hf_split_to_rag_jsonl(\"neural-bridge/rag-dataset-1200\", \"train\", \"out/hf_qa_train.jsonl\",\n",
    "                      include_q_and_a_in_content=False, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def upload_to_gcs(local_path: str, bucket: str, dest_path: str):\n",
    "    client = storage.Client()\n",
    "    blob = client.bucket(bucket).blob(dest_path)\n",
    "    blob.upload_from_filename(local_path)\n",
    "    return f\"gs://{bucket}/{dest_path}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adk_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
